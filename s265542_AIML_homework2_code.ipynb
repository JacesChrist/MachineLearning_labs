{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91FEBddOS00l",
        "colab_type": "text"
      },
      "source": [
        "**Install requirements, Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8OJfsa1Srrw",
        "colab_type": "code",
        "outputId": "2ed2a4cc-2f23-4f63-fb9e-296089bfc7a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# install packets (first time need env restart)\n",
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.4.2'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\n",
        "!pip3 install --upgrade 'pillow'\n",
        "\n",
        "# import libraries\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision.datasets import VisionDataset\n",
        "from PIL import Image\n",
        "import os.path\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "\n",
        "# time finished task function\n",
        "def donetime(start=None):\n",
        "  if start != None:\n",
        "    if ((time.time() - start)/60) < 60:\n",
        "      print('DONE (time {:4.2f} m)\\n'.format((time.time() - start)/60))\n",
        "    else:\n",
        "      print('DONE (time {:4.2f} h)\\n'.format((time.time() - start)/3600))\n",
        "  else:\n",
        "    print('\\nDONE')\n",
        "  return\n",
        "\n",
        "donetime()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.3.1) (1.17.4)\n",
            "Requirement already satisfied: torchvision==0.4.2 in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2) (1.3.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2) (6.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2) (1.17.4)\n",
            "Requirement already satisfied: Pillow-SIMD in /usr/local/lib/python3.6/dist-packages (6.0.0.post0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already up-to-date: pillow in /usr/local/lib/python3.6/dist-packages (6.2.1)\n",
            "\n",
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SW-CEUzwS-_j",
        "colab_type": "text"
      },
      "source": [
        "**Set Arguments, Clone git repository**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XTUt5YHTD8h",
        "colab_type": "code",
        "outputId": "2820d164-b283-4afd-8164-f2af4067fc3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# set default parameters\n",
        "DEVICE = 'cuda'\n",
        "NUM_CLASSES = 101\n",
        "BATCH_SIZE = 256 \n",
        "MOMENTUM = 0.9    #rho  \n",
        "WEIGHT_DECAY = 5e-5  \n",
        "GAMMA = 0.1        \n",
        "LOG_FREQUENCY = 10\n",
        "DATA_DIR = 'Homework2-Caltech101/101_ObjectCategories'\n",
        "\n",
        "# clone git repo, errer if interrupted while cloning github repo!\n",
        "if not os.path.isdir('./Homework2-Caltech101'):\n",
        "  print('Cloning github repository')\n",
        "  !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n",
        "\n",
        "# simple status bar \n",
        "def statusBar(actual, finish): #no other prints!\n",
        "  print(end=\"\\r\", flush=True)\n",
        "  print('[ ', end = '') \n",
        "  for i in range(actual):\n",
        "    print('###', end = '')\n",
        "  if actual != (finish -1):\n",
        "    print('#>-', end = '')\n",
        "  for i in range(finish - actual - 2):\n",
        "    print('---', end = '')\n",
        "  print(' ]', end = '')\n",
        "  return\n",
        "\n",
        "donetime() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning github repository\n",
            "Cloning into 'Homework2-Caltech101'...\n",
            "remote: Enumerating objects: 9256, done.\u001b[K\n",
            "remote: Total 9256 (delta 0), reused 0 (delta 0), pack-reused 9256\u001b[K\n",
            "Receiving objects: 100% (9256/9256), 129.48 MiB | 30.26 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Checking out files: 100% (9149/9149), done.\n",
            "\n",
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_D_ZJX9TNu6",
        "colab_type": "text"
      },
      "source": [
        "**Custom Dataset Class** *1A 1B*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ8XY-35TOb1",
        "colab_type": "code",
        "outputId": "d9af34d1-b0d6-4b28-d623-0850753c1202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# proper image loader\n",
        "def pil_loader(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "# dataset class\n",
        "class Caltech(VisionDataset):\n",
        "    # initialization\n",
        "    def __init__(self, root, split='train', transform=None, target_transform=None):\n",
        "        super(Caltech, self).__init__(root, transform=transform, target_transform=target_transform)\n",
        "\n",
        "        self.split = split\n",
        "\n",
        "        self.dataset = [] # (PILimage, labelID)\n",
        "        self.labels = [] # (label) ID by index\n",
        "        \n",
        "        if self.split == 'train':\n",
        "          text = open(\"./Homework2-Caltech101/train.txt\",\"r\")\n",
        "        else:\n",
        "          if self.split == 'test':\n",
        "            text = open(\"./Homework2-Caltech101/test.txt\",\"r\")\n",
        "          else:\n",
        "            print(\"ERROR\")\n",
        "\n",
        "        readText = text.readlines()\n",
        "        for iterText in readText:\n",
        "          label, image = os.path.split(iterText)\n",
        "          if not label == 'BACKGROUND_Google': \n",
        "            if not label in self.labels:\n",
        "              self.labels.append(label)\n",
        "            self.dataset.append((pil_loader(DATA_DIR + '/' + iterText.replace('\\n','')), self.labels.index(label)))\n",
        "        print(split, \"correctly loaded\")\n",
        "    # getter\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "    # get lenght\n",
        "    def __len__(self):\n",
        "        length = len(self.dataset)\n",
        "        return length\n",
        "\n",
        "donetime()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XujQPqbNTWQw",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Transformations, Dataset and Dataloader** *2A*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvY93IKoTWwP",
        "colab_type": "code",
        "outputId": "7dd6cca2-6056-4b52-8df6-338c94f63035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# define transformations (default) 2C\n",
        "#train_transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ]) # validation has same transformations of train\n",
        "#test_transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ])\n",
        "\n",
        "# define transformations with standard alexnet mean and standard deviation 3B\n",
        "#train_transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
        "#test_transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
        "\n",
        "# define transformations with processing 4A\n",
        "#train_transform = transforms.Compose([transforms.RandomHorizontalFlip(0.5), transforms.RandomVerticalFlip(0.5), transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
        "train_transform = transforms.Compose([transforms.RandomGrayscale(0.5), transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
        "#train_transform = transforms.Compose([transforms.RandomGrayscale(0.1), transforms.RandomHorizontalFlip(0.5), transforms.RandomVerticalFlip(0.5), transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
        "test_transform = transforms.Compose([transforms.CenterCrop(224), transforms.Resize(256), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
        "\n",
        "# create datasets\n",
        "tosplit_dataset = Caltech(DATA_DIR,'train',train_transform, None)\n",
        "\n",
        "train_indexes = [idx for idx in range(len(tosplit_dataset)) if idx % 2]\n",
        "validation_indexes = [idx for idx in range(len(tosplit_dataset)) if not idx % 2]\n",
        "validation_dataset = Subset(tosplit_dataset, validation_indexes)\n",
        "train_dataset = Subset(tosplit_dataset, train_indexes)\n",
        "\n",
        "test_dataset = Caltech(DATA_DIR,'test',test_transform,None)\n",
        "\n",
        "print(\"TRAIN\", train_dataset.__len__(), \"tuple\")\n",
        "print(\"VALIDATION\", validation_dataset.__len__(), \"tuple\")\n",
        "print(\"TEST\", test_dataset.__len__(), \"tuple\\n\")\n",
        "\n",
        "# prepare dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "donetime()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train correctly loaded\n",
            "test correctly loaded\n",
            "TRAIN 2892 tuple\n",
            "VALIDATION 2892 tuple\n",
            "TEST 2893 tuple\n",
            "\n",
            "\n",
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsXd1KfaTjzE",
        "colab_type": "text"
      },
      "source": [
        "**Main function Train Validation Test, Output Function**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT7dAMP5TkPn",
        "colab_type": "code",
        "outputId": "73109320-48a6-4fa1-c840-3a3977da732f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#train model\n",
        "def functionTrainValidationTest(net, LRn, NUM_EPOCHSn, STEP_SIZEn, type=None):\n",
        "  print('STARTING TRAIN-VALIDATION-TEST {} (LR {}, NUM_EPOCHS {}, STEP_SIZE {})\\n'.format(type, LRn, NUM_EPOCHSn, STEP_SIZEn))\n",
        "\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  if type != '3D' and type != '3E':\n",
        "    parameters_to_optimize = net.parameters()\n",
        "  else:\n",
        "    if type == '3D': # 3D optimize only fully connected layers\n",
        "      parameters_to_optimize = net.classifier.parameters() \n",
        "    if type == '3E': # 3E optimize only convolutional layers\n",
        "      parameters_to_optimize = net.features.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr=LRn, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZEn, gamma=GAMMA)\n",
        "\n",
        "  # By default, everything is loaded to cpu\n",
        "  net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "  cudnn.benchmark # Calling this optimizes runtime\n",
        "\n",
        "  current_step = 0\n",
        "\n",
        "  best_accuracy = 0\n",
        "\n",
        "  scores = [] #(epoch, accuracy, actualLOSS)\n",
        "  best_accuracy = 0\n",
        "\n",
        "  # Start iterating over the epochs\n",
        "  for epoch in range(NUM_EPOCHSn):\n",
        "    #print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "\n",
        "    # Iterate over the dataset\n",
        "    for images, labels in train_dataloader:\n",
        "      # Bring data over the device of choice\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      net.train() # Sets module in training mode\n",
        "\n",
        "      # PyTorch, by default, accumulates gradients after each backward pass\n",
        "      # We need to manually set the gradients to zero before starting a new iteration\n",
        "      optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "      # Forward pass to the network\n",
        "      outputs = net(images)\n",
        "\n",
        "      # Compute loss based on output and ground truth\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      actualLOSS = loss.item()\n",
        "\n",
        "      '''# Log loss\n",
        "      if current_step % LOG_FREQUENCY == 0:\n",
        "        print('Step {}, Loss {}'.format(current_step, loss.item())) '''\n",
        "\n",
        "      # Compute gradients for each layer and update weights\n",
        "      loss.backward()  # backward pass: computes gradients\n",
        "      optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "      current_step += 1\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step() \n",
        "\n",
        "    # VALIDATION each epoch\n",
        "\n",
        "    net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "    net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "    running_corrects = 0\n",
        "    for images, labels in validation_dataloader:\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs = net(images)\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = running_corrects / float(len(validation_dataset))\n",
        "    scores.append((epoch, accuracy, actualLOSS))\n",
        "    #print('Validation Accuracy: {}, epoch {}, loss {}'.format(accuracy, epoch,  actualLOSS))\n",
        "    \n",
        "    statusBar(epoch, NUM_EPOCHSn)\n",
        "\n",
        "    # save best net\n",
        "    if accuracy >= best_accuracy: # if equal take last\n",
        "      best_accuracy = accuracy\n",
        "      best_net = deepcopy(net)\n",
        "\n",
        "  print(\"\\n\\nVALIDATION Final Results (epoch, accuracy, loss):\")\n",
        "  for tup in scores:\n",
        "    print(tup)\n",
        "  x = []\n",
        "  y = []\n",
        "  # accuracy per epoch graph\n",
        "  for tup in scores:\n",
        "    x.append(tup[0])\n",
        "    y.append(tup[1])\n",
        "  print('')\n",
        "  plt.plot(x, y)\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()\n",
        "  x = []\n",
        "  y = []\n",
        "  # loss per epoch graph\n",
        "  for tup in scores:\n",
        "    x.append(tup[0])\n",
        "    y.append(tup[2])\n",
        "  print('')\n",
        "  plt.plot(x, y)\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()\n",
        "  print('\\nBest model accuracy: {}\\n'.format(best_accuracy))\n",
        "\n",
        "  # TEST\n",
        "\n",
        "  best_net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "  best_net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "  running_corrects = 0\n",
        "  for images, labels in test_dataloader:\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    outputs = best_net(images)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len(test_dataset))\n",
        "  print('TEST Accuracy Final Result: {}\\n'.format(accuracy))\n",
        "  \n",
        "  return\n",
        "\n",
        "donetime()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-aIoe4qw3qU",
        "colab_type": "text"
      },
      "source": [
        "***TRAIN-VALIDATION-TEST***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENc-4GeGtN3I",
        "colab_type": "text"
      },
      "source": [
        "**Train and Validation tuning LR, NUM_EPOCH, STEP_SIZE** *2C*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3U93LBNtI0w",
        "colab_type": "code",
        "outputId": "f85539a6-ba8d-4fc6-e2c7-1594a146a3d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "startTime = time.time()\n",
        "\n",
        "LR = 0.01\n",
        "NUM_EPOCHS = 70\n",
        "STEP_SIZE = 20\n",
        "\n",
        "alnet = alexnet()\n",
        "alnet.classifier[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "#functionTrainValidationTest(alnet, LR, NUM_EPOCHS, STEP_SIZE, '2C')\n",
        "\n",
        "donetime(startTime)\n",
        "\n",
        "# 0.001 30  20    0.09\n",
        "# 0.005 50  40    0.36\n",
        "# 0.01  50  40    0.52\n",
        "\n",
        "# 0.01  40  20    0.30\n",
        "# 0.01  40  30    0.41\n",
        "# 0.01  50  20    0.34\n",
        "# 0.05  50  20    0.40\n",
        "# 0.1   60  20    0.01\n",
        "# 0.1   70  20    0.32"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DONE (time 0.01 m)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA2AdLHoyLrq",
        "colab_type": "text"
      },
      "source": [
        "**Test on AlexNet pretrained with ImageNet database** *3C*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJzOWpl0yMNr",
        "colab_type": "code",
        "outputId": "c0c6571b-b309-4cd0-fb37-98f503176538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "startTime = time.time()\n",
        "\n",
        "LR = 0.005\n",
        "NUM_EPOCHS = 50\n",
        "STEP_SIZE = 40\n",
        "\n",
        "net = alexnet(pretrained=True)\n",
        "\n",
        "# functionTrainValidationTest(net, LR, NUM_EPOCHS, STEP_SIZE, '3C')\n",
        "\n",
        "donetime(startTime)\n",
        "\n",
        "# 0.01  50  40  0.01\n",
        "# 0.001 50  40  0.66 \n",
        "# 0.001 60  20  0.58\n",
        "# 0.005 60  20  0.68 \n",
        "# 0.005 50  40  0.71"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 151MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DONE (time 0.05 m)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ll4jGLlzH7L",
        "colab_type": "text"
      },
      "source": [
        "**Test on AlexNet pretrained only fully connected and only convolutional layers** *3D 3E*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLOjbuvlBA4K",
        "colab_type": "code",
        "outputId": "21a2474c-9b0d-4a22-8e70-a7805cac74f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "net = alexnet(pretrained=True)\n",
        "\n",
        "LR = 0.005\n",
        "NUM_EPOCHS = 50\n",
        "STEP_SIZE = 40\n",
        "\n",
        "net = alexnet(pretrained=True)\n",
        "\n",
        "#functionTrainValidationTest(net, LR, NUM_EPOCHS, STEP_SIZE, '3D')\n",
        "\n",
        "net = alexnet(pretrained=True)\n",
        "\n",
        "#functionTrainValidationTest(net, LR, NUM_EPOCHS, STEP_SIZE, '3E')\n",
        "\n",
        "donetime(startTime)\n",
        "\n",
        "# 0.005 50  40  0.84\n",
        "\n",
        "# 0.005 50  40  0.54\n",
        "# 0.001 50  40  0.41"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DONE (time 0.11 m)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvyMoncktRYL",
        "colab_type": "text"
      },
      "source": [
        "**Test on AlexNet pretrained with training transformations** *4A*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dvpbde0tRpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "startTime = time.time()\n",
        "\n",
        "LR = 0.005\n",
        "NUM_EPOCHS = 50\n",
        "STEP_SIZE = 40\n",
        "\n",
        "net = alexnet(pretrained=True)\n",
        "\n",
        "functionTrainValidationTest(net, LR, NUM_EPOCHS, STEP_SIZE, '4A')\n",
        "\n",
        "donetime(startTime)\n",
        "\n",
        "# 0.005 50  40  orizontalFlip verticalFlip  0.69 \n",
        "# 0.005 50  40  grayScale                   0.60\n",
        "# 0.005 50  40  all                         0.60"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}